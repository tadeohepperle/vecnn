{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num omitted: 1027\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# we did some late stage rework to improve the parallelism of the vecnn implementation, so we need to filter out the old results\n",
    "# and only use new ones from here on. This script does that.\n",
    "# old results in thesis_experiments/a10m_filtered_no_old_vecnn_threaded.csv\n",
    "# new results in thesis_experiments/a10m_filtered_new_vecnn_threaded.csv\n",
    "path = 'thesis_experiments'\n",
    "files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.startswith('a10m') and f.endswith('.csv') and \"filtered\" not in f]\n",
    "files.sort()\n",
    "all_files = ''\n",
    "n = 0\n",
    "for file in files:\n",
    "    with open(os.path.join(path, file), 'r') as f:\n",
    "        n+=1\n",
    "        all_files += f.read()\n",
    "rows = all_files.split('\\n')\n",
    "\n",
    "out_file: str = 'thesis_experiments/a10m_filtered_no_old_vecnn_threaded.csv'\n",
    "out_string: str = ''\n",
    "omitted_rows = []\n",
    "for i, row in (enumerate(rows)):\n",
    "    if row.startswith('#') or row.isspace() or len(row) == 0:\n",
    "        continue\n",
    "    if row.startswith('n,dims') and i > 0:\n",
    "        continue\n",
    "    assert(row.startswith('10120191') or row.startswith('n,dims'))\n",
    "    if \"Ensemble\" in row or ((\"vecnn\" in row or \"RNNGraph\" in row) and \"threaded: True\" in row):\n",
    "        omitted_rows.append(row)\n",
    "        continue\n",
    "    out_string += row + '\\n'\n",
    "with open(out_file, 'w') as f:\n",
    "    f.write(out_string)\n",
    "\n",
    "print(f'Num omitted: {len(omitted_rows)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_110365/1189371862.py:5: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df[\"a\"].iloc[-1] = 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame(columns=['a', \"b\", \"c\"], data= np.zeros((10,3)))\n",
    "\n",
    "df[\"a\"].iloc[-1] = 1\n",
    "\n",
    "\n",
    "df[\"a\"].iloc[-1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
