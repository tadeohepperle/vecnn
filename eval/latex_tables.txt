



\begin{table}
\caption{experiment: rep=1, level\_norm\_param=0.3, ef\_construction=60, m\_max=20, m\_max\_0=40, distance=Dot, dist=Dot, k=30, ef=60, start\_candidates=1, n\_queries=1000}
\label{hnsw_effect_of_n}
\begin{tabular}{rrrrl}
\toprule
n & build_ms & recall & time_ms & model \\
\midrule
10000 & 1548.237 & 0.975 & 0.198 & SliceS2HnswParams \\
10000 & 1560.561 & 0.975 & 0.198 & SliceS2HnswParams \\
30000 & 6609.136 & 0.963 & 0.317 & SliceS2HnswParams \\
30000 & 6628.716 & 0.963 & 0.321 & SliceS2HnswParams \\
100000 & 32093.129 & 0.954 & 0.418 & SliceS2HnswParams \\
300000 & 121519.670 & 0.926 & 0.475 & SliceS2HnswParams \\
1000000 & 472444.100 & 0.910 & 0.531 & SliceS2HnswParams \\
3000000 & 1773315.000 & 0.891 & 0.652 & SliceS2HnswParams \\
10000000 & 6847348.500 & 0.860 & 0.764 & SliceS2HnswParams \\
\bottomrule
\end{tabular}
\end{table}




\begin{table}
\caption{experiment: rep=10, n=100000, model=SliceS2HnswParams, level\_norm\_param=0.3, ef\_construction=40, distance=Dot, k=30, ef=60, n\_queries=100}
\label{exp_hnsw_effect_of_m_max}
\begin{tabular}{rrrrrrr}
\toprule
build_ndc & build_ms & recall & ndc & time_ms & m_max & m_max_0 \\
\midrule
36808102 & 13249.221 & 0.780 & 499.520 & 0.245 & 8 & 16 \\
48070390 & 17453.629 & 0.870 & 648.240 & 0.313 & 12 & 24 \\
58388815 & 21242.572 & 0.921 & 796.530 & 0.382 & 16 & 32 \\
68256596 & 25070.785 & 0.932 & 944.840 & 0.455 & 20 & 40 \\
77681703 & 28861.855 & 0.952 & 1073.430 & 0.517 & 24 & 48 \\
86781248 & 32408.568 & 0.967 & 1207.920 & 0.584 & 28 & 56 \\
95641999 & 35788.406 & 0.973 & 1337.820 & 0.644 & 32 & 64 \\
104292049 & 39173.336 & 0.976 & 1447.430 & 0.698 & 36 & 72 \\
112772348 & 42454.195 & 0.978 & 1557.000 & 0.749 & 40 & 80 \\
119418513 & 44997.336 & 0.980 & 1621.790 & 0.781 & 44 & 88 \\
125592102 & 47446.934 & 0.983 & 1706.110 & 0.819 & 48 & 96 \\
\bottomrule
\end{tabular}
\end{table}




\begin{table}
\caption{experiment: rep=1, n=100000, model=SliceS2HnswParams, level\_norm\_param=0.3, m\_max=20, m\_max\_0=40, distance=Dot, k=30, ef=60, n\_queries=1000}
\label{exp_hnsw_effect_of_ef_construction}
\begin{tabular}{rrrrrr}
\toprule
build_ndc & build_ms & recall & ndc & time_ms & ef_construction \\
\midrule
57288264 & 21519.887 & 0.934 & 945.833 & 0.454 & 30 \\
68256596 & 26567.621 & 0.942 & 951.465 & 0.454 & 40 \\
78697221 & 31643.450 & 0.949 & 954.864 & 0.456 & 50 \\
88751642 & 36373.715 & 0.954 & 954.500 & 0.457 & 60 \\
98509666 & 41057.207 & 0.956 & 955.501 & 0.457 & 70 \\
108029599 & 45691.520 & 0.955 & 956.396 & 0.458 & 80 \\
117317580 & 50133.516 & 0.954 & 959.150 & 0.458 & 90 \\
126404169 & 54606.316 & 0.955 & 956.667 & 0.457 & 100 \\
135342504 & 58985.200 & 0.954 & 956.864 & 0.457 & 110 \\
144123590 & 63431.020 & 0.954 & 958.383 & 0.458 & 120 \\
152761979 & 68265.670 & 0.955 & 958.824 & 0.458 & 130 \\
161274875 & 73649.160 & 0.955 & 960.158 & 0.458 & 140 \\
169652552 & 78147.810 & 0.956 & 959.992 & 0.459 & 150 \\
177922105 & 82852.970 & 0.956 & 959.988 & 0.459 & 160 \\
186068823 & 87205.690 & 0.956 & 960.456 & 0.459 & 170 \\
194151974 & 92060.836 & 0.956 & 959.826 & 0.459 & 180 \\
202099637 & 96275.160 & 0.957 & 960.128 & 0.459 & 190 \\
209973660 & 101291.830 & 0.957 & 959.952 & 0.459 & 200 \\
\bottomrule
\end{tabular}
\end{table}




\begin{table}
\caption{experiment: n=100000, build\_ndc=68256596, model=SliceS2HnswParams, level\_norm\_param=0.3, ef\_construction=40, m\_max=20, m\_max\_0=40, distance=Dot, n\_queries=100}
\label{hnsw_ef_search}
\begin{tabular}{rrrrrrr}
\toprule
rep & build_ms & recall & ndc & time_ms & k & ef \\
\midrule
20 & 25235.543 & 0.857 & 605.370 & 0.278 & 30 & 30 \\
10 & 25235.547 & 0.908 & 733.280 & 0.343 & 30 & 40 \\
10 & 25235.547 & 0.917 & 834.890 & 0.397 & 30 & 50 \\
10 & 25235.547 & 0.932 & 944.840 & 0.455 & 30 & 60 \\
10 & 25235.547 & 0.937 & 1043.480 & 0.508 & 30 & 70 \\
10 & 25235.547 & 0.941 & 1136.230 & 0.558 & 30 & 80 \\
10 & 25235.547 & 0.947 & 1236.740 & 0.613 & 30 & 90 \\
10 & 25235.547 & 0.951 & 1331.650 & 0.663 & 30 & 100 \\
10 & 25235.547 & 0.954 & 1427.740 & 0.716 & 30 & 110 \\
10 & 25235.547 & 0.956 & 1520.500 & 0.764 & 30 & 120 \\
10 & 25235.547 & 0.966 & 1631.420 & 0.829 & 30 & 130 \\
10 & 25235.547 & 0.966 & 1722.670 & 0.878 & 30 & 140 \\
10 & 25235.547 & 0.968 & 1817.980 & 0.931 & 30 & 150 \\
10 & 25235.547 & 0.969 & 1906.980 & 0.979 & 30 & 160 \\
10 & 25235.547 & 0.969 & 1995.340 & 1.030 & 30 & 170 \\
10 & 25235.547 & 0.972 & 2082.470 & 1.080 & 30 & 180 \\
10 & 25235.547 & 0.973 & 2168.070 & 1.126 & 30 & 190 \\
10 & 25235.547 & 0.973 & 2257.250 & 1.177 & 30 & 200 \\
\bottomrule
\end{tabular}
\end{table}




\begin{table}
\caption{experiment: n=100000, build\_ndc=68256596, model=SliceS2HnswParams, level\_norm\_param=0.3, ef\_construction=40, m\_max=20, m\_max\_0=40, distance=Dot, n\_queries=100}
\label{hnsw_k}
\begin{tabular}{rrrrrrr}
\toprule
rep & build_ms & recall & ndc & time_ms & k & ef \\
\midrule
20 & 25235.543 & 0.857 & 605.370 & 0.278 & 30 & 30 \\
10 & 25235.547 & 0.895 & 733.280 & 0.342 & 40 & 40 \\
10 & 25235.547 & 0.898 & 834.890 & 0.396 & 50 & 50 \\
10 & 25235.547 & 0.911 & 944.840 & 0.454 & 60 & 60 \\
10 & 25235.547 & 0.915 & 1043.480 & 0.507 & 70 & 70 \\
10 & 25235.547 & 0.915 & 1136.230 & 0.558 & 80 & 80 \\
10 & 25235.547 & 0.919 & 1236.740 & 0.610 & 90 & 90 \\
10 & 25235.547 & 0.920 & 1331.650 & 0.660 & 100 & 100 \\
10 & 25235.547 & 0.923 & 1427.740 & 0.712 & 110 & 110 \\
10 & 25235.547 & 0.924 & 1520.500 & 0.761 & 120 & 120 \\
10 & 25235.547 & 0.934 & 1631.420 & 0.823 & 130 & 130 \\
10 & 25235.547 & 0.936 & 1722.670 & 0.873 & 140 & 140 \\
10 & 25235.547 & 0.937 & 1817.980 & 0.925 & 150 & 150 \\
10 & 25235.547 & 0.939 & 1906.980 & 0.974 & 160 & 160 \\
10 & 25235.547 & 0.940 & 1995.340 & 1.026 & 170 & 170 \\
10 & 25235.547 & 0.941 & 2082.470 & 1.074 & 180 & 180 \\
10 & 25235.547 & 0.940 & 2168.070 & 1.122 & 190 & 190 \\
10 & 25235.547 & 0.940 & 2257.250 & 1.171 & 200 & 200 \\
\bottomrule
\end{tabular}
\end{table}




\begin{table}
\caption{experiment: rep=1, n=100000, model=SliceS2HnswParams, ef\_construction=40, m\_max=20, m\_max\_0=40, distance=Dot, k=30, ef=60, n\_queries=1000}
\label{exp_hnsw_effect_of_level_norm}
\begin{tabular}{rrrrrr}
\toprule
build_ndc & build_ms & recall & ndc & time_ms & level_norm_param \\
\midrule
71480325 & 27947.188 & 0.946 & 1005.852 & 0.483 & 0.000 \\
71480325 & 27978.068 & 0.946 & 1005.852 & 0.484 & 0.050 \\
69095268 & 26918.863 & 0.948 & 956.369 & 0.465 & 0.100 \\
67409624 & 26807.525 & 0.945 & 956.116 & 0.463 & 0.150 \\
67737278 & 26632.697 & 0.941 & 947.586 & 0.457 & 0.200 \\
68486997 & 26925.525 & 0.944 & 960.102 & 0.460 & 0.250 \\
68256596 & 26486.280 & 0.942 & 951.465 & 0.454 & 0.300 \\
70264320 & 27294.887 & 0.945 & 967.274 & 0.460 & 0.350 \\
71547316 & 27601.082 & 0.941 & 973.157 & 0.462 & 0.400 \\
72252087 & 27786.744 & 0.944 & 964.004 & 0.455 & 0.450 \\
74464445 & 28346.994 & 0.943 & 978.981 & 0.458 & 0.500 \\
76074030 & 28696.996 & 0.948 & 994.594 & 0.464 & 0.550 \\
78125994 & 29509.424 & 0.945 & 1003.657 & 0.464 & 0.600 \\
79980745 & 30024.832 & 0.945 & 1010.975 & 0.467 & 0.650 \\
82141055 & 30580.764 & 0.946 & 1022.250 & 0.468 & 0.700 \\
83914803 & 31170.762 & 0.943 & 1024.223 & 0.466 & 0.750 \\
86115446 & 31834.549 & 0.943 & 1038.131 & 0.469 & 0.800 \\
88132095 & 32220.360 & 0.945 & 1046.826 & 0.471 & 0.850 \\
90455238 & 33012.125 & 0.942 & 1056.526 & 0.472 & 0.900 \\
92437024 & 33668.700 & 0.945 & 1063.898 & 0.473 & 0.950 \\
94722962 & 34345.074 & 0.944 & 1073.462 & 0.475 & 1.000 \\
\bottomrule
\end{tabular}
\end{table}




\begin{table}
\caption{experiment: n=100000, build\_ndc=176353688, model=RNNGraphParams, outer\_loops=3, inner\_loops=4, max\_neighbors\_after\_reverse\_pruning=40, initial\_neighbors=40, distance=Dot}
\label{rnn_ef_search}
\begin{tabular}{rrrrrlrrrr}
\toprule
rep & build_ms & recall & ndc & time_ms & dist & k & ef & start_candidates & n_queries \\
\midrule
5 & 35608.100 & 0.963 & 1391.811 & 0.550 & Dot & 30 & 60 & 1.000 & 1000 \\
5 & 35608.100 & 0.964 & 1387.460 & 0.545 & Dot & 30 & 60 & 2.000 & 1000 \\
5 & 35608.100 & 0.964 & 1404.381 & 0.547 & Dot & 30 & 60 & 3.000 & 1000 \\
5 & 35608.100 & 0.964 & 1404.859 & 0.547 & Dot & 30 & 60 & 4.000 & 1000 \\
5 & 35608.100 & 0.964 & 1403.975 & 0.546 & Dot & 30 & 60 & 5.000 & 1000 \\
5 & 35608.100 & 0.964 & 1387.272 & 0.542 & Dot & 30 & 60 & 6.000 & 1000 \\
5 & 35608.100 & 0.964 & 1384.855 & 0.542 & Dot & 30 & 60 & 7.000 & 1000 \\
5 & 35608.100 & 0.964 & 1378.623 & 0.539 & Dot & 30 & 60 & 8.000 & 1000 \\
5 & 35608.100 & 0.964 & 1379.375 & 0.540 & Dot & 30 & 60 & 9.000 & 1000 \\
5 & 35608.100 & 0.964 & 1379.338 & 0.539 & Dot & 30 & 60 & 10.000 & 1000 \\
5 & 35608.100 & 0.964 & 1375.024 & 0.538 & Dot & 30 & 60 & 11.000 & 1000 \\
5 & 35608.100 & 0.964 & 1370.499 & 0.536 & Dot & 30 & 60 & 12.000 & 1000 \\
5 & 35608.100 & 0.964 & 1370.277 & 0.536 & Dot & 30 & 60 & 13.000 & 1000 \\
5 & 35608.100 & 0.964 & 1366.488 & 0.535 & Dot & 30 & 60 & 14.000 & 1000 \\
5 & 35608.100 & 0.964 & 1367.336 & 0.535 & Dot & 30 & 60 & 15.000 & 1000 \\
5 & 35608.100 & 0.964 & 1367.352 & 0.535 & Dot & 30 & 60 & 16.000 & 1000 \\
5 & 35608.100 & 0.964 & 1366.740 & 0.535 & Dot & 30 & 60 & 17.000 & 1000 \\
5 & 35608.100 & 0.964 & 1385.852 & 0.539 & Dot & 30 & 60 & 18.000 & 1000 \\
5 & 35608.100 & 0.964 & 1386.760 & 0.539 & Dot & 30 & 60 & 19.000 & 1000 \\
5 & 35608.100 & 0.964 & 1387.261 & 0.539 & Dot & 30 & 60 & 20.000 & 1000 \\
10 & 35583.867 & 0.908 & 823.330 & 0.357 & NaN & 30 & 30 & NaN & 100 \\
5 & 35583.867 & 0.932 & 1001.280 & 0.390 & NaN & 30 & 40 & NaN & 100 \\
5 & 35583.867 & 0.947 & 1195.440 & 0.470 & NaN & 30 & 50 & NaN & 100 \\
5 & 35583.867 & 0.960 & 1389.810 & 0.545 & NaN & 30 & 60 & NaN & 100 \\
5 & 35583.867 & 0.972 & 1562.620 & 0.617 & NaN & 30 & 70 & NaN & 100 \\
5 & 35583.867 & 0.976 & 1728.240 & 0.685 & NaN & 30 & 80 & NaN & 100 \\
5 & 35583.867 & 0.979 & 1897.290 & 0.755 & NaN & 30 & 90 & NaN & 100 \\
5 & 35583.867 & 0.983 & 2071.280 & 0.825 & NaN & 30 & 100 & NaN & 100 \\
5 & 35583.867 & 0.986 & 2244.950 & 0.896 & NaN & 30 & 110 & NaN & 100 \\
5 & 35583.867 & 0.988 & 2400.920 & 0.959 & NaN & 30 & 120 & NaN & 100 \\
5 & 35583.867 & 0.988 & 2554.860 & 1.023 & NaN & 30 & 130 & NaN & 100 \\
5 & 35583.867 & 0.990 & 2717.120 & 1.092 & NaN & 30 & 140 & NaN & 100 \\
5 & 35583.867 & 0.992 & 2865.040 & 1.154 & NaN & 30 & 150 & NaN & 100 \\
5 & 35583.867 & 0.993 & 3034.470 & 1.225 & NaN & 30 & 160 & NaN & 100 \\
5 & 35583.867 & 0.994 & 3200.410 & 1.293 & NaN & 30 & 170 & NaN & 100 \\
5 & 35583.867 & 0.994 & 3343.150 & 1.357 & NaN & 30 & 180 & NaN & 100 \\
5 & 35583.867 & 0.995 & 3496.310 & 1.422 & NaN & 30 & 190 & NaN & 100 \\
5 & 35583.867 & 0.995 & 3643.700 & 1.485 & NaN & 30 & 200 & NaN & 100 \\
\bottomrule
\end{tabular}
\end{table}




\begin{table}
\caption{experiment: n=100000, build\_ndc=176353688, model=RNNGraphParams, outer\_loops=3, inner\_loops=4, max\_neighbors\_after\_reverse\_pruning=40, initial\_neighbors=40, distance=Dot}
\label{rnn_k}
\begin{tabular}{rrrrrlrrrr}
\toprule
rep & build_ms & recall & ndc & time_ms & dist & k & ef & start_candidates & n_queries \\
\midrule
10 & 35583.867 & 0.908 & 823.330 & 0.357 & NaN & 30 & 30 & NaN & 100 \\
5 & 35583.867 & 0.915 & 1001.280 & 0.389 & NaN & 40 & 40 & NaN & 100 \\
5 & 35583.867 & 0.921 & 1195.440 & 0.469 & NaN & 50 & 50 & NaN & 100 \\
5 & 35583.867 & 0.931 & 1389.810 & 0.544 & NaN & 60 & 60 & NaN & 100 \\
5 & 35583.867 & 0.937 & 1562.620 & 0.616 & NaN & 70 & 70 & NaN & 100 \\
5 & 35583.867 & 0.939 & 1728.240 & 0.683 & NaN & 80 & 80 & NaN & 100 \\
5 & 35583.867 & 0.939 & 1897.290 & 0.754 & NaN & 90 & 90 & NaN & 100 \\
5 & 35583.867 & 0.943 & 2071.280 & 0.829 & NaN & 100 & 100 & NaN & 100 \\
5 & 35583.867 & 0.948 & 2244.950 & 0.895 & NaN & 110 & 110 & NaN & 100 \\
5 & 35583.867 & 0.952 & 2400.920 & 0.958 & NaN & 120 & 120 & NaN & 100 \\
5 & 35583.867 & 0.953 & 2554.860 & 1.022 & NaN & 130 & 130 & NaN & 100 \\
5 & 35583.867 & 0.955 & 2717.120 & 1.091 & NaN & 140 & 140 & NaN & 100 \\
5 & 35583.867 & 0.956 & 2865.040 & 1.154 & NaN & 150 & 150 & NaN & 100 \\
5 & 35583.867 & 0.956 & 3034.470 & 1.224 & NaN & 160 & 160 & NaN & 100 \\
5 & 35583.867 & 0.958 & 3200.410 & 1.294 & NaN & 170 & 170 & NaN & 100 \\
5 & 35583.867 & 0.959 & 3343.150 & 1.357 & NaN & 180 & 180 & NaN & 100 \\
5 & 35583.867 & 0.960 & 3496.310 & 1.421 & NaN & 190 & 190 & NaN & 100 \\
5 & 35583.867 & 0.961 & 3643.700 & 1.485 & NaN & 200 & 200 & NaN & 100 \\
\bottomrule
\end{tabular}
\end{table}




\begin{table}
\caption{experiment: rep=1, n=100000, model=RNNGraphParams, outer\_loops=1, max\_neighbors\_after\_reverse\_pruning=40, initial\_neighbors=40, distance=Dot, k=30, ef=60, n\_queries=10000}
\label{rnn_inner_loops}
\begin{tabular}{rrrrrr}
\toprule
build_ndc & build_ms & recall & ndc & time_ms & inner_loops \\
\midrule
18093216 & 5020.736 & 0.182 & 6890.852 & 2.561 & 1 \\
47360250 & 10345.127 & 0.498 & 6034.579 & 2.273 & 2 \\
84119168 & 16507.530 & 0.787 & 5115.407 & 1.929 & 3 \\
121094600 & 22545.460 & 0.902 & 4362.885 & 1.660 & 4 \\
153637297 & 27923.172 & 0.936 & 3589.844 & 1.374 & 5 \\
178045375 & 32049.865 & 0.946 & 2997.026 & 1.153 & 6 \\
193790275 & 34962.348 & 0.948 & 2541.850 & 0.978 & 7 \\
202938930 & 36881.090 & 0.946 & 2225.653 & 0.858 & 8 \\
207904596 & 38107.043 & 0.943 & 2025.744 & 0.781 & 9 \\
210504295 & 38888.445 & 0.941 & 1924.066 & 0.740 & 10 \\
211870880 & 39362.184 & 0.940 & 1898.839 & 0.730 & 11 \\
212615549 & 39702.180 & 0.939 & 1859.634 & 0.715 & 12 \\
213060685 & 39920.290 & 0.939 & 1840.141 & 0.705 & 13 \\
213376286 & 40097.645 & 0.938 & 1839.188 & 0.705 & 14 \\
213615193 & 40276.246 & 0.938 & 1841.292 & 0.705 & 15 \\
213823209 & 40407.457 & 0.938 & 1831.368 & 0.699 & 16 \\
214023428 & 40556.465 & 0.938 & 1835.402 & 0.702 & 17 \\
214214488 & 40692.906 & 0.938 & 1837.908 & 0.703 & 18 \\
214398580 & 40798.285 & 0.938 & 1830.072 & 0.699 & 19 \\
214590119 & 40932.210 & 0.938 & 1836.777 & 0.702 & 20 \\
214774712 & 41059.910 & 0.938 & 1838.198 & 0.703 & 21 \\
214957327 & 41165.105 & 0.938 & 1831.366 & 0.699 & 22 \\
215146610 & 41301.223 & 0.938 & 1836.009 & 0.701 & 23 \\
215332255 & 41426.324 & 0.938 & 1838.064 & 0.702 & 24 \\
\bottomrule
\end{tabular}
\end{table}




\begin{table}
\caption{experiment: n=100000, model=RNNGraphParams, max\_neighbors\_after\_reverse\_pruning=40, initial\_neighbors=40, distance=Dot, k=30, ef=60, n\_queries=10000}
\label{rnn_outer_loops}
\begin{tabular}{rrrrrrrr}
\toprule
rep & build_ndc & build_ms & recall & ndc & time_ms & outer_loops & inner_loops \\
\midrule
2 & 219783208 & 44369.375 & 0.938 & 1838.062 & 0.703 & 1 & 48 \\
1 & 254077209 & 51423.470 & 0.964 & 1382.157 & 0.526 & 2 & 24 \\
1 & 278413344 & 57052.504 & 0.965 & 1330.426 & 0.509 & 3 & 16 \\
1 & 300314810 & 62016.973 & 0.966 & 1307.586 & 0.500 & 4 & 12 \\
1 & 330186360 & 68798.240 & 0.966 & 1281.142 & 0.494 & 6 & 8 \\
1 & 334576984 & 71148.380 & 0.966 & 1262.517 & 0.490 & 8 & 6 \\
1 & 334562698 & 74580.040 & 0.965 & 1296.079 & 0.505 & 12 & 4 \\
1 & 356807453 & 84494.220 & 0.964 & 1363.873 & 0.529 & 24 & 2 \\
\bottomrule
\end{tabular}
\end{table}




\begin{table}
\caption{experiment: rep=1, n=100000, model=EnsembleParams, n\_vp\_trees=6, same\_chunk\_m\_max=16, m\_max=20, m\_max\_0=40, level\_norm=0.0, distance=Dot, strategy=BruteForceKNN, n\_candidates=0, k=30, ef=60, n\_queries=1000}
\label{exp_ensemble_effect_of_chunk_size}
\begin{tabular}{rrrrrr}
\toprule
build_ndc & build_ms & recall & ndc & time_ms & max_chunk_size \\
\midrule
23231916 & 4633.604 & 0.849 & 1463.603 & 0.704 & 64 \\
37880172 & 7033.389 & 0.885 & 1374.646 & 0.663 & 128 \\
67176684 & 11909.979 & 0.904 & 1294.068 & 0.626 & 256 \\
125770284 & 21123.740 & 0.914 & 1238.871 & 0.601 & 512 \\
125770284 & 21150.023 & 0.914 & 1238.871 & 0.602 & 768 \\
242957676 & 39286.080 & 0.924 & 1181.423 & 0.573 & 1024 \\
242957676 & 39230.754 & 0.924 & 1181.423 & 0.573 & 1280 \\
242957676 & 39242.310 & 0.924 & 1181.423 & 0.567 & 1536 \\
477332652 & 75316.570 & 0.925 & 1133.217 & 0.537 & 1792 \\
477332652 & 75278.960 & 0.925 & 1133.217 & 0.537 & 2048 \\
\bottomrule
\end{tabular}
\end{table}




\begin{table}
\caption{experiment: rep=1, n=100000, model=EnsembleParams, n\_vp\_trees=6, max\_chunk\_size=256, same\_chunk\_m\_max=16, m\_max=20, m\_max\_0=40, distance=Dot, strategy=BruteForceKNN, n\_candidates=0, k=30, ef=60, n\_queries=100}
\label{exp_ensemble_effect_of_level_norm}
\begin{tabular}{rrrrrr}
\toprule
build_ndc & build_ms & recall & ndc & time_ms & level_norm \\
\midrule
67176684 & 11983.370 & 0.904 & 1298.970 & 0.638 & 0.000 \\
67176684 & 11844.803 & 0.904 & 1298.970 & 0.633 & 0.050 \\
67176694 & 11831.283 & 0.893 & 1211.190 & 0.602 & 0.100 \\
67185330 & 11831.979 & 0.906 & 1279.460 & 0.629 & 0.150 \\
67582072 & 11894.173 & 0.899 & 1314.880 & 0.639 & 0.200 \\
68580208 & 12057.014 & 0.888 & 1264.260 & 0.613 & 0.250 \\
69840598 & 12256.352 & 0.906 & 1292.180 & 0.625 & 0.300 \\
70696168 & 12415.186 & 0.894 & 1292.390 & 0.617 & 0.350 \\
71308657 & 12527.430 & 0.894 & 1283.050 & 0.612 & 0.400 \\
74012118 & 12987.272 & 0.898 & 1265.780 & 0.602 & 0.450 \\
78254720 & 13691.054 & 0.895 & 1292.270 & 0.611 & 0.500 \\
82302120 & 14366.479 & 0.886 & 1325.870 & 0.624 & 0.550 \\
79988519 & 14013.448 & 0.904 & 1299.320 & 0.606 & 0.600 \\
82689681 & 14471.490 & 0.904 & 1314.690 & 0.613 & 0.650 \\
86909207 & 15180.615 & 0.889 & 1328.610 & 0.618 & 0.700 \\
92127998 & 16039.421 & 0.897 & 1318.270 & 0.608 & 0.750 \\
93988306 & 16364.342 & 0.888 & 1335.360 & 0.614 & 0.800 \\
99482533 & 17282.863 & 0.888 & 1357.310 & 0.625 & 0.850 \\
92119102 & 16120.451 & 0.899 & 1365.860 & 0.626 & 0.900 \\
95278398 & 16651.816 & 0.888 & 1349.140 & 0.614 & 0.950 \\
100148576 & 17482.188 & 0.891 & 1379.040 & 0.627 & 1.000 \\
\bottomrule
\end{tabular}
\end{table}




\begin{table}
\caption{experiment: rep=1, n=100000, model=EnsembleParams, max\_chunk\_size=256, same\_chunk\_m\_max=16, m\_max=20, m\_max\_0=40, level\_norm=0.0, distance=Dot, strategy=BruteForceKNN, n\_candidates=0, k=30, ef=60, n\_queries=1000}
\label{exp_ensemble_effect_of_n_vp_trees}
\begin{tabular}{rrrrrr}
\toprule
build_ndc & build_ms & recall & ndc & time_ms & n_vp_trees \\
\midrule
22392228 & 3893.338 & 0.714 & 1214.588 & 0.571 & 2 \\
33588342 & 5887.060 & 0.839 & 1487.469 & 0.700 & 3 \\
44784456 & 7892.651 & 0.881 & 1404.008 & 0.661 & 4 \\
55980570 & 9893.602 & 0.896 & 1331.287 & 0.630 & 5 \\
67176684 & 11887.347 & 0.904 & 1294.068 & 0.611 & 6 \\
78372798 & 13878.215 & 0.908 & 1266.866 & 0.600 & 7 \\
89568912 & 15865.055 & 0.906 & 1234.900 & 0.587 & 8 \\
100765026 & 17853.984 & 0.912 & 1215.717 & 0.578 & 9 \\
111961140 & 19843.889 & 0.911 & 1209.119 & 0.575 & 10 \\
123157254 & 21826.754 & 0.917 & 1194.160 & 0.569 & 11 \\
134353368 & 23811.094 & 0.919 & 1182.068 & 0.563 & 12 \\
145549482 & 25793.723 & 0.924 & 1175.655 & 0.560 & 13 \\
156745596 & 27779.021 & 0.926 & 1173.933 & 0.559 & 14 \\
167941710 & 29759.135 & 0.923 & 1166.601 & 0.555 & 15 \\
179137824 & 31740.627 & 0.926 & 1161.913 & 0.553 & 16 \\
190333938 & 33722.117 & 0.925 & 1151.812 & 0.549 & 17 \\
201530052 & 35701.660 & 0.921 & 1155.254 & 0.549 & 18 \\
212726166 & 37677.120 & 0.919 & 1145.443 & 0.545 & 19 \\
223922280 & 39663.170 & 0.919 & 1141.077 & 0.542 & 20 \\
\bottomrule
\end{tabular}
\end{table}




\begin{table}
\caption{experiment: rep=1, n=100000, model=EnsembleParams, n\_vp\_trees=6, max\_chunk\_size=256, same\_chunk\_m\_max=16, m\_max=20, m\_max\_0=40, level\_norm=0.0, distance=Dot, strategy=BruteForceKNN, k=30, ef=60, n\_queries=500}
\label{exp_ensemble_effect_of_multiple_vantage_points}
\begin{tabular}{rrrrrr}
\toprule
build_ndc & build_ms & recall & ndc & time_ms & n_candidates \\
\midrule
67176684 & 11980.480 & 0.910 & 1306.020 & 0.629 & 1 \\
67766472 & 12082.381 & 0.899 & 1294.828 & 0.618 & 4 \\
68552772 & 12191.335 & 0.901 & 1363.216 & 0.646 & 8 \\
70125084 & 12380.241 & 0.896 & 1355.470 & 0.641 & 16 \\
73268556 & 12681.312 & 0.905 & 1363.224 & 0.646 & 32 \\
79550892 & 13425.583 & 0.903 & 1384.490 & 0.654 & 64 \\
\bottomrule
\end{tabular}
\end{table}
